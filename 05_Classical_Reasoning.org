#+Title: Logic and Proof
#+Author: [[http://www.andrew.cmu.edu/user/avigad][Jeremy Avigad]], [[http://www.andrew.cmu.edu/user/rlewis1/][Robert Y. Lewis]],  [[http://www.contrib.andrew.cmu.edu/~fpv/][Floris van Doorn]]

* Classical Reasoning
:PROPERTIES:
  :CUSTOM_ID: Classical_Reasoning
:END:      

If we take all the rules of propositional logic we have seen so far
and exclude /reductio ad absurdum/, or proof by contradiction, we have
what is known as /intuitionistic logic/. In intuitionistic logic, it
is possible to view proofs in computational terms: a proof of $A
\wedge B$ is a proof of $A$ paired with a proof of $B$, a proof of $A
\to B$ is a procedure which transforms evidence for $A$ into evidence
for $B$, and a proof of $A \vee B$ is a proof of one or the other,
tagged so that we know which is the case. The /ex falso/ rule makes
sense only because we expect that there is no proof of falsity; it is
like the empty data type.

Proof by contradiction does not fit it well with this world view: from
a proof of a contradiction from $\neg A$, we are supposed to magically
produce a proof of $A$. We will see that with proof by contradiction,
we can prove the law of the excluded middle, $A \vee \neg A$. From a
computational perspective, this would say that we can ways decide
whether or not $A$ is true.

Classical reasoning does introduce a number of principles into logic,
however, that can be used to simplify reasoning. In this chapter, we
will consider these principles, and see how they follow from the basic
rules.

** Proof by Contradiction

Remember that in natural deduction, proof by contradiction is
expressed by the following pattern:
\begin{prooftree}
\AXM{}
\RLM{1}
\UIM{\neg A}
\noLine
\UIM{\vdots}
\noLine
\UIM{\bot}
\RLM{1}
\UIM{A}
\end{prooftree}
The assumption $\neg A$ is canceled at the final inference. 

In Lean, the inference is named =by_contradiction=, and since it is a
classical rule, we have to use the command =open classical= before it
is available. Once we do so, the pattern of inference is expressed as
follows:
#+BEGIN_SRC lean
open classical

variable (A : Prop)

example : A :=
by_contradiction
  (assume H : ¬ A,
    show false, from sorry)
#+END_SRC

One of them most important consequences of this rule is the law of the
excluded middle. In mathematical arguments, one often splits
a proof into two cases, assuming first $A$ and then $\neg A$. Using
the elimination rule for disjunction, this is equivalent to using $A
\vee \neg A$, a classical principle known as the law of the excluded
middle. Here is a proof of this, in natural deduction, using a proof
by contradiction:
\begin{center}
\AXM{}
\RLM{2}
\UIM{\neg (A \vee \neg A)}
\AXM{}
\RLM{1}
\UIM{A}
\UIM{A \vee \neg A}
\BIM{\bot}
\RLM{1}
\UIM{\neg A}
\UIM{A \vee \neg A}
\AXM{}
\RLM{1}
\UIM{\neg (A \vee \neg A)}
\BIM{\bot}
\RLM{2}
\UIM{A \vee \neg A}
\DP
\end{center}
Here is the same proof rendered in Lean:
#+BEGIN_SRC lean
open classical

variable (A : Prop)

example : A ∨ ¬ A :=
by_contradiction
  (assume H1 : ¬ (A ∨ ¬ A),
    have H2 : ¬ A, from
      assume H3 : A,
      have H4 : A ∨ ¬ A, from or.inl H3,
      show false, from H1 H4,
    have H5 : A ∨ ¬ A, from or.inr H2,
    show false, from H1 H5)
#+END_SRC
The principle is known as the law of the excluded middle because it
says that a proposition =A= is either true or false; there is no
middle ground. As a result, the theorem is named =em= in the Lean
library. For any proposition =A=, =em A= denotes a proof of =A ∨ ¬ A=,
and you are free to use it any time =classical= is open:
#+BEGIN_SRC lean
open classical

example (A : Prop) : A ∨ ¬ A :=
or.elim (em A)
  (suppose A, or.inl this)
  (suppose ¬ A, or.inr this)
#+END_SRC 
Or even more simply:
#+BEGIN_SRC lean
open classical

example (A : Prop) : A ∨ ¬ A :=
em A
#+END_SRC
In fact, we can go in the other direction, and use the law of the
excluded middle to justify proof by contradiction. You are asked to do
this in the exercises. 

Proof by contradiction is also equivalent to the principle $¬ ¬ A ↔
A$. The implication from right to left holds intuitionistically; the
other implication is classical, and is known as /double-negation
elimination/. Here is a proof in natural deduction:
\begin{center}
\AXM{}
\RLM{2}
\UIM{\neg \neg A}
\AXM{}
\RLM{1}
\UIM{\neg A}
\BIM{\bot}
\RLM{1}
\UIM{A}
\AXM{}
\RLM{1}
\UIM{\neg A}
\AXM{}
\RLM{2}
\UIM{A}
\BIM{\bot}
\RLM{1}
\UIM{\neg \neg A}
\RLM{2}
\BIM{\neg \neg A \liff A}
\DP
\end{center}
And here is the corresponding proof in Lean:
#+BEGIN_SRC lean
open classical

example (A : Prop) : ¬ ¬ A ↔ A :=
iff.intro
  (assume H1 : ¬ ¬ A,
    show A, from by_contradiction
      (assume H2 : ¬ A, 
        show false, from H1 H2))
  (assume H1 : A,
    show ¬ ¬ A, from assume H2 : ¬ A, H2 H1)
#+END_SRC

In the next section, we will derive a number of classical rules and
equivalences. These are tricky to prove. In general, to use classical
reasoning in natural deduction, we need to extend the general
heuristic presented in Section [[file:02_Natural_Deduction_for_Propositional_Logic.org::#Forward_and_Backward_Reasoning][Forward and Backward Reasoning]] as follows:
1. First, work backwards from the conclusion, using the introduction
   rules. 
2. When you have run out things to do in the first step, use
   elimination rules to work forwards.
3. If all else fails, use a proof by contradiction.

Sometimes a proof by contradiction is necessary, but when it isn't, it
can be less informative by a direct proof. Suppose, for example, we
want to prove $A \wedge B \wedge C \to D$. In a direct proof, we
assume $A$, $B$, and $C$, and work towards $D$. Along the way, we will
derive other consequences of $A$, $B$, and $C$, and these may be
useful in other contexts. If we use proof by contradition, on the
other hand, we assume $A$, $B$, $C$, and $\neg D$, and try to prove
$\bot$. In that case, we are working in an inconsistent context; any
auxiliary results we may obtain that way are subsumed by the fact that
we ultimately $\bot$ is a consequence of the hypotheses.


** Some Classical Principles
:PROPERTIES:
  :CUSTOM_ID: Some_Classical_Principles
:END:

We have already seen that $A \vee \neg A$ and $\neg \neg A \liff A$ are
two important theorems of classical propositional logic. In this
section we will provide some more theorems, rules, and
equivalences. Some will be proved here, but most will be left to you
in the exercises. In ordinary mathematics, these are generally used
without comment. It is nice to know, however, that they can all be
justified using the basic rules of classical natural deduction.

If $A \to B$ is any implication, the assertion $\neg B \to \neg A$ is
known as the /contrapositive/. Every implication implies its
contrapositive, and the other direction is true classically:
\begin{center}
\AXM{\neg B \to \neg A}
\AXM{}
\RLM{1}
\UIM{\neg B}
\BIM{\neg A}
\AXM{}
\RLM{2}
\UIM{A}
\BIM{\bot}
\RLM{1}
\UIM{B}
\RLM{2}
\UIM{A \to B}
\DP
\end{center}

Here is another example. Intuitively, asserting "if A then B" is
equivalent to saying that it cannot be the case that A is true and B
is false. Classical reasoning is needed to get us from the second
statement to the first.
\begin{center}
\AXM{}
\RLM{3}
\UIM{\neg (A \wedge \neg B)}
\AXM{}
\RLM{2}
\UIM{A}
\AXM{}
\RLM{1}
\UIM{\neg B}
\BIM{A \wedge \neg B}
\BIM{\bot}
\RLM{1}
\UIM{B}
\RLM{2}
\UIM{A \to B}
\RLM{3}
\UIM{\neg (A \wedge \neg B) \to (A \to B)}
\DP
\end{center}
Here is the same proof, rendered in Lean:
#+BEGIN_SRC lean
open classical

variables (A B : Prop)

example (H : ¬ (A ∧ ¬ B)) : A → B :=
suppose A,
show B, from
  by_contradiction
    (suppose ¬ B,
      have A ∧ ¬ B, from and.intro `A` this,
      show false, from H this)
#+END_SRC

Implication can be rewritten in terms of disjunction and
negation:
\[
A \to B \liff \neg A \vee B
\]
The forward direction requires classical reasoning. 

The following equivalences are known as De Morgan's laws:
\begin{align*}
  \neg (A \vee B) & \liff \neg A \wedge \neg B \\
  \neg (A \wedge B) & \liff \neg A \vee \neg B 
\end{align*}
The forward direction of the second of these requires classical
reasoning.

Using these identities, we can always push negations down to
propositional variables. For example, we have
\begin{align*}
  \neg (\neg A \wedge B \to C) 
    & \liff \neg (\neg (\neg A \wedge B) \vee C) \\
    & \liff \neg \neg (\neg A \wedge B) \wedge \neg C \\
    & \liff \neg A \wedge B \wedge \neg C
\end{align*}
A formula built up from $\wedge$, $\vee$, and $\neg$ in which
negations only occur at variables is said to be in /negation normal
form/.

In fact, using distributivity laws, one can go on to ensure that all
the disjunctions are on the outside, so that the formulas is a big or
of and's of propositional variables and negated propositional
variables. Such a formula is said to be in /disjunctive normal
form/. Alternatively, all the and's can be brought to the
outside. Such a formula is said to be in /conjunctive normal form/. An
exercise below, however, shows that putting formulas in disjunctive or
conjunctive normal form can make them much longer.

** Exercises

1. Show how to derive the proof-by-contradiction rule from the law of
   the excluded middle, using the other rules of natural deduction.

2. Give a natural deduction proof of $\neg (A \wedge B)$ from $\neg A
   \vee \neg B$. (You do not need to use proof by contradiction.)

3. Construct a natural deduction proof of $\neg A \vee \neg B$ from
   $\neg (A \wedge B)$. You can do it as follows:

   1. First, prove $\neg B$, and hence $\neg A \vee \neg B$, from
      $\neg (A \wedge B)$ and $A$.

   2. Use this to construct a proof of $\neg A$, and hence $\neg A
      \vee \neg B$, from $\neg (A \wedge B)$ and $\neg (\neg A \vee
      \neg B)$.

   3. Use this to construct a proof of a contradiction from $\neg (A
      \wedge B)$ and $\neg (\neg A \vee \neg B)$.

   4. Using proof by contradiction, this gives you a proof of $\neg A
      \vee \neg B$ from $\neg (A \wedge B)$.

4. Give a natural deduction proof of $\neg A \vee B$ from $A \to
   B$. You may use the law of the excluded middle.

5. Put $(A \vee B) \wedge (C \vee D) \wedge (E \vee F)$ in disjunctive
   normal form, that is, write it as a big "or" of "and"'s.

6. Prove =¬ (A ∧ B) → ¬ A ∨ ¬ B= by replacing the sorry's below by
   proofs.

   #+BEGIN_SRC lean
   open classical
   variables {A B C : Prop}

   -- Prove ¬ (A ∧ B) → ¬ A ∨ ¬ B by replacing the sorry's below 
   -- by proofs.

   lemma step1 (H₁ : ¬ (A ∧ B)) (H₂ : A) : ¬ A ∨ ¬ B :=
   have ¬ B, from sorry,
   show ¬ A ∨ ¬ B, from or.inr this

   lemma step2 (H₁ : ¬ (A ∧ B)) (H₂ : ¬ (¬ A ∨ ¬ B)) : false :=
   have ¬ A, from
     suppose A,
     have ¬ A ∨ ¬ B, from step1 H₁ `A`,
     show false, from H₂ this,
   show false, from sorry

   theorem step3 (H : ¬ (A ∧ B)) : ¬ A ∨ ¬ B :=
   by_contradiction
     (assume H' : ¬ (¬ A ∨ ¬ B),
       show false, from step2 H H')
   #+END_SRC

7. Also do these:

   #+BEGIN_SRC lean
   open classical
   variables {A B C : Prop}

   example (H : ¬ B → ¬ A) : A → B :=
   sorry

   example (H : A → B) : ¬ A ∨ B :=
   sorry
   #+END_SRC



